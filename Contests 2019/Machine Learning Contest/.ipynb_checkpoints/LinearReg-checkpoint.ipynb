{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qdFaw5h-cU7M"
   },
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "colab_type": "code",
    "id": "ugv76kstcU7N",
    "outputId": "4ba1ff55-75f0-45c8-8372-9ba853703062"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import gridspec\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3rJyBrkFcU7T"
   },
   "source": [
    "## Importing and Processing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B4gWKQI4cU7U"
   },
   "source": [
    "### Importing and Viewing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dayplSiAcU7W"
   },
   "source": [
    "*Importing Data from csv file*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ck1WgBcEcU7X"
   },
   "outputs": [],
   "source": [
    "df=     #Read the file from the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wUgrchSIcU7c"
   },
   "source": [
    "*Printing Data and its Statistics*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fh6WBMYXcU7d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.reindex(np.random.permutation(df.index))\t\t\t#Shuffle\n",
    "print (df)\n",
    "print (df.describe())\t\t\t\t\t#Gives statitics of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U0l0QpofcU7j",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = #select inputs\n",
    "y = df[\"quality\"]\n",
    "print (X.columns.values)\n",
    "print (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rgfLaVmrcU7o"
   },
   "outputs": [],
   "source": [
    "#converting pandas Dataframe to Numpy Arrays\n",
    "X = X.to_numpy()\n",
    "y = y.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QGeRUaX2cU7s"
   },
   "source": [
    "### Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ch20d_yfcU7u"
   },
   "source": [
    "*Preprocessing Data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rU44o6CCcU7v"
   },
   "outputs": [],
   "source": [
    "def Feature_Normalize(X):\n",
    "    \"\"\"\n",
    "    Normalizes the features in X. returns a normalized version of X.\n",
    "    \"\"\"\n",
    "    #Write your code here\n",
    "    return X_norm, mu, sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i76sqzxfcU7z"
   },
   "source": [
    "### Splitting the Data for Training and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a9X97wO6cU70"
   },
   "source": [
    "*Splitting Data to Train and Test sets to train and evaluate the Model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zJEnWnM2cU72"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yO8hiqsncU76"
   },
   "outputs": [],
   "source": [
    "X_train = Feature_Normalize(X_train)[0]\n",
    "X_test = Feature_Normalize(X_test)[0]\n",
    "X_train = np.c_[np.ones(X_train.shape[0]), X_train] \n",
    "X_test = np.c_[np.ones(X_test.shape[0]), X_test] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YHnKi9D5cU7_",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print (\"Shape of Training Set is\",X_train.shape)\n",
    "print (\"Shape of Test Set is\",X_test.shape)\n",
    "\n",
    "print (\"Shape of Training Set is\",y_train.shape)\n",
    "print (\"Shape of Test Set is\",y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8jTHYd-xcU8D"
   },
   "source": [
    "## Training and Validating the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GADLulSGkIB4"
   },
   "source": [
    "The objective of linear regression is to minimize the cost function\n",
    "\n",
    "$$ J(\\theta) = \\frac{1}{2m} \\sum_{i=1}^m \\left( h_{\\theta}(x^{(i)}) - y^{(i)}\\right)^2 +\\frac{\\lambda}{2m}\\sum_{j=1}^n {\\theta_j}^2$$\n",
    "where the hypothesis $h_\\theta(x)$ is given by the linear model$$ h_\\theta(x) = \\theta^Tx = \\sum_{i=0}^n \\theta_ix_i$$\n",
    "\n",
    "Recall that the parameters of your model are the $\\theta_j$ values. These are the values you will adjust to minimize cost $J(\\theta)$. One way to do this is to use the batch gradient descent algorithm. In batch gradient descent, each iteration performs the update\n",
    "\n",
    "$$ \\theta_j = \\theta_j - \\alpha \\frac{1}{m} \\frac{\\partial J(\\theta)}{\\partial \\theta_j} \\quad \\forall j\\geq1  \\qquad \\text{simultaneously update } \\theta_j \\text{ for all } j$$\n",
    "where, $$\\frac{\\partial J(\\theta)}{\\partial \\theta_j} = \\sum_{i=1}^m \\left( h_\\theta(x^{(i)}) - y^{(i)}\\right)x_j^{(i)} + \\frac{\\lambda}{m}\\theta_j$$\n",
    "With each step of gradient descent, your parameters $\\theta_j$ come closer to the optimal values that will achieve the lowest cost J($\\theta$).\n",
    "\n",
    "$\\textbf{Note}$: Its your wish to implement the regularisation or you can ignore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L3KEVyzacU8F"
   },
   "source": [
    "*Compute Cost function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "huNpQah8cU8G"
   },
   "outputs": [],
   "source": [
    "def Cost_Function(X, y, theta):\n",
    "    \"\"\"\n",
    "    Compute cost for linear regression with multiple variables.\n",
    "    Computes the cost of using theta as the parameter for linear regression to fit the data points in X and y.\n",
    "    \"\"\"\n",
    "    #Write your code here\n",
    "    \n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b1uVNxXtcU8K"
   },
   "source": [
    "*Gradient Descent*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iUw1uKTfcU8L"
   },
   "outputs": [],
   "source": [
    "def GradientDescent(X, y, theta, lr):\n",
    "    \"\"\"\n",
    "    Performs gradient descent to learn theta.\n",
    "    Updates theta by taking num_iters gradient steps with learning rate alpha.\n",
    "    \"\"\"\n",
    "    #Write your code here\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q2BqTbBbcU8T"
   },
   "source": [
    "*Function to Calculate Validation Loss*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tPzctcLacU8U"
   },
   "outputs": [],
   "source": [
    "def Validation_Loss_Function(y_pred,y):\n",
    "    \"\"\"\n",
    "    Function to calculate Validation Loss\n",
    "    \"\"\"\n",
    "    m = y.shape[0]\n",
    "    loss = np.square(y_pred-y)/(m)\n",
    "    loss = np.sum(loss)\n",
    "    loss = np.sqrt(loss)\n",
    "    return loss   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_guzmjWocU8Y"
   },
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0lII4nqfcU8Z"
   },
   "outputs": [],
   "source": [
    "def Training_and_Validation(X_train,y_train,X_test,y_test,lr=,epochs=):\n",
    "    \"\"\"\n",
    "    Training Linear Regression Model\n",
    "    \"\"\"\n",
    "    #Rearrange all the following lines to get a perfect plot\n",
    "    s = X_train.shape[1]\n",
    "    theta = np.zeros(s)\n",
    "    Training_Loss = []\n",
    "    Validation_Loss = []\n",
    "    \n",
    "    #Train your model here\n",
    "    \n",
    "    \n",
    "    plt.plot(Training_Loss,'r')\n",
    "    plt.plot(Validation_Loss,'y')\n",
    "    plt.show()\n",
    "    \n",
    "    print (\"Final Training Loss is equal to \",Training_Loss[-1])\n",
    "    print (\"Final Validation Loss is equal to \",Validation_Loss[-1])\n",
    "    \n",
    "    return theta  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2PNbGfg1cU8d"
   },
   "outputs": [],
   "source": [
    "theta = Training_and_Validation(X_train,y_train,X_test,y_test)\n",
    "print(theta)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "LinearReg.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
